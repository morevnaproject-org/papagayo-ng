# -*- coding: ISO-8859-1 -*-
# generated by wxGlade 0.3.5.1 on Wed Apr 13 16:04:35 2005

# Papagayo-NG, a lip-sync tool for use with several different animation suites
# Original Copyright (C) 2005 Mike Clifton
# Contact information at http://www.lostmarble.com
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

# import os
# from utilities import Worker, WorkerSignals
import importlib
import json
import sys
import os
import tarfile
import time
from functools import partial
from pprint import pprint

from PySide2.QtCore import QFile
from PySide2 import QtCore, QtGui, QtWidgets
from PySide2.QtUiTools import QUiLoader as uic

import urllib.request
import io
from zipfile import ZipFile
import utilities
import platform
import random
import re

from WaveformViewRewrite import WaveformView
from MouthViewQT import MouthView
# end wxGlade

from AboutBoxQT import AboutBox
from SettingsQT import SettingsWindow
import LipsyncDoc

app_title = "Papagayo-NG"
lipsync_extension_list = ("pgo", "pg2")
audio_extension_list = ("wav", "mp3", "aiff", "aif", "au", "snd", "mov", "m4a")
export_file_types = ("txt", "json", "dat")
exporter_list = ("MOHO", "ALELO", "Images", "JSON")
lipsync_extension = "".join(" *.{}".format(ext) for ext in lipsync_extension_list)[1:]
audio_extensions = "".join(" *.{}".format(ext) for ext in audio_extension_list)[1:]
open_wildcard = "{} and sound files ({} {})".format(app_title, audio_extensions, lipsync_extension)
save_wildcard = "{} files ({})".format(app_title, lipsync_extension)


class DropFilter(QtCore.QObject):
    def eventFilter(self, obj, event):
        if event.type() == QtCore.QEvent.DragEnter:
            if event.mimeData().hasUrls():
                event.accept()
            else:
                event.ignore()
            return True
        elif event.type() == QtCore.QEvent.Drop:
            if event.mimeData().hasUrls():
                # event.accept()
                for url in event.mimeData().urls():
                    if sys.platform == "darwin":
                        from Foundation import NSURL
                        fname = str(NSURL.URLWithString_(str(url.toString())).filePathURL().path())
                        obj.topLevelWidget().lip_sync_frame.open(fname)
                    else:
                        fname = str(url.toLocalFile())
                        obj.topLevelWidget().lip_sync_frame.open(fname)
                return True
            else:
                event.ignore()
                return False

        else:
            return False


def sort_mouth_list_order(elem):
    try:
        return int(elem.split("-")[0])
    except ValueError:
        return hash(elem)


def open_file_no_gui(path, parent):
    importlib.reload(LipsyncDoc)  # This makes the CLI version work on the first try but is very hacky
    langman = LipsyncDoc.LanguageManager()
    langman.init_languages()
    ini_path = os.path.join(utilities.get_app_data_path(), "settings.ini")
    config = QtCore.QSettings(ini_path, QtCore.QSettings.IniFormat)
    doc = LipsyncDoc.LipsyncDoc(langman, parent)
    if path.endswith(lipsync_extension_list):
        if path.endswith(lipsync_extension_list[0]):
            # open a lipsync project
            doc.open(path)
        elif path.endswith(lipsync_extension_list[1]):
            # open a json based lipsync project
            doc.open_json(path)
        if doc.sound is None:
            print("Could not load Sound file.")
            print(doc.soundPath)
            return None
    else:
        # open an audio file
        doc.fps = int(config.value("LastFPS", 24))
        doc.open_audio(path)
        if doc.sound is None:
            doc = None
        else:
            if len(doc.project_node.children) < 1:
                doc.current_voice = LipsyncDoc.LipSyncObject(object_type="voice", name="Voice 1",
                                                             parent=doc.project_node)
            elif not doc.current_voice:
                doc.current_voice = doc.project_node.children[0]
            doc.auto_recognize_phoneme()
    return doc


class LipsyncFrame:
    def __init__(self):
        QtCore.QCoreApplication.setAttribute(QtCore.Qt.AA_ShareOpenGLContexts)
        self.app = QtWidgets.QApplication(sys.argv)
        self.loader = None
        self.ui_file = None
        self.ui = None
        self.doc = None
        self.about_dlg = None
        self.settings_dlg = None
        self.ui_path = os.path.join(utilities.get_main_dir(), "rsrc", "papagayo-ng2.ui")
        self.main_window = self.load_ui_widget(self.ui_path)
        self.main_window.setWindowTitle("%s" % app_title)
        self.main_window.lip_sync_frame = self
        ini_path = os.path.join(utilities.get_app_data_path(), "settings.ini")
        self.config = QtCore.QSettings(ini_path, QtCore.QSettings.IniFormat)
        self.config.setFallbacksEnabled(False)  # File only, not registry or or.

        tree_style = r'''QTreeView::branch:has-siblings:!adjoins-item {
                             border-image: url(./rsrc/vline.png) 0;}               
                         QTreeView::branch:has-siblings:adjoins-item {
                             border-image: url(./rsrc/branch-more.png) 0;}
                         QTreeView::branch:!has-children:!has-siblings:adjoins-item {
                             border-image: url(./rsrc/branch-end.png) 0;}
                         QTreeView::branch:has-children:!has-siblings:closed,
                         QTreeView::branch:closed:has-children:has-siblings {
                                 border-image: none;
                                 image: url(./rsrc/branch-closed.png); }
                         QTreeView::branch:open:has-children:!has-siblings,
                         QTreeView::branch:open:has-children:has-siblings  {
                                 border-image: none;
                                 image: url(./rsrc/branch-open.png); }'''
        self.main_window.parent_tags.setStyleSheet(tree_style)

        # TODO: need a good description for this stuff
        mouth_list = list(self.main_window.mouth_view.mouths.keys())
        mouth_list.sort(key=sort_mouth_list_order)
        for mouth in mouth_list:
            self.main_window.mouth_choice.addItem(mouth)
        self.main_window.mouth_choice.setCurrentIndex(0)
        self.main_window.mouth_choice.current_mouth = self.main_window.mouth_choice.currentText()
        self.langman = LipsyncDoc.LanguageManager()
        self.langman.init_languages()
        language_list = list(self.langman.language_table.keys())
        language_list.sort()

        c = 0
        select = 0
        for language in language_list:
            self.main_window.language_choice.addItem(language)
            if language == "English":
                select = c
            c += 1
        self.main_window.language_choice.setCurrentIndex(select)

        # setup phonemeset initialisation here
        self.phonemeset = LipsyncDoc.PhonemeSet()
        for name in self.phonemeset.alternatives:
            self.main_window.phoneme_set.addItem(name)
        current_index = self.main_window.phoneme_set.findText(self.phonemeset.selected_set)
        self.main_window.phoneme_set.setCurrentIndex(current_index)

        c = 0
        select = 0
        for exporter in exporter_list:
            self.main_window.export_combo.addItem(exporter)
            if exporter == "MOHO":
                select = c
            c += 1
        self.main_window.export_combo.setCurrentIndex(select)
        self.app.aboutToQuit.connect(self.on_close)
        self.ignore_text_changes = False
        # This adds our statuses to the statusbar
        self.mainframe_statusbar_fields = [app_title, "Stopped"]
        self.play_status = QtWidgets.QLabel()
        self.play_status.setText(self.mainframe_statusbar_fields[1])
        # An empty Label to add a separator
        self.sep_status = QtWidgets.QLabel()
        self.sep_status.setText(u"")
        self.main_window.statusbar.addPermanentWidget(self.sep_status)
        self.main_window.statusbar.addPermanentWidget(self.play_status)
        self.main_window.statusbar.showMessage(self.mainframe_statusbar_fields[0])
        self.status_progress = QtWidgets.QProgressBar()
        self.main_window.statusbar.addPermanentWidget(self.status_progress)
        self.status_progress.hide()
        # This is for the buttons to add and remove voices from the TabBar
        self.tab_widgets = QtWidgets.QWidget()
        self.tab_layout = QtWidgets.QHBoxLayout()
        self.tab_add_button = QtWidgets.QToolButton()
        self.tab_add_button.setText("+")
        self.tab_remove_button = QtWidgets.QToolButton()
        self.tab_remove_button.setText("-")
        self.tab_layout.addWidget(self.tab_add_button)
        self.tab_layout.addWidget(self.tab_remove_button)
        self.tab_layout.setContentsMargins(0, 0, 0, 0)
        self.tab_layout.setSpacing(1)
        self.tab_widgets.setContentsMargins(0, 0, 0, 0)
        self.tab_widgets.setLayout(self.tab_layout)
        self.main_window.current_voice.setCornerWidget(self.tab_widgets)
        # Connect Events
        self.main_window.action_play.triggered.connect(self.on_play)
        self.main_window.action_stop.triggered.connect(self.on_stop)
        self.main_window.action_exit.triggered.connect(self.quit_application)
        self.main_window.action_open.triggered.connect(self.on_open)
        self.main_window.action_save.triggered.connect(self.on_save)
        self.main_window.action_save_as.triggered.connect(self.on_save_as)
        self.main_window.action_zoom_in.triggered.connect(self.main_window.waveform_view.on_zoom_in)
        self.main_window.action_zoom_out.triggered.connect(self.main_window.waveform_view.on_zoom_out)
        self.main_window.action_reset_zoom.triggered.connect(self.main_window.waveform_view.on_zoom_reset)
        self.main_window.action_settings.triggered.connect(self.show_settings)
        self.main_window.action_select_as_current_set.triggered.connect(self.set_current_phoneme_set)
        self.main_window.reload_dict_button.clicked.connect(self.on_reload_dictionary)
        self.main_window.waveform_view.horizontalScrollBar().sliderMoved.connect(
            self.main_window.waveform_view.on_slider_change)
        self.main_window.action_help_topics.triggered.connect(self.on_help)
        self.main_window.action_about_papagayo_ng.triggered.connect(self.on_about)
        self.main_window.export_combo.currentIndexChanged.connect(self.on_export_choice)
        self.main_window.voice_name_input.textChanged.connect(self.on_voice_name)
        self.main_window.export_button.clicked.connect(self.on_voice_export)
        self.main_window.breakdown_button.clicked.connect(self.on_voice_breakdown)
        self.main_window.voice_recognition_button.clicked.connect(self.on_voice_recognize)
        self.main_window.choose_imageset_button.clicked.connect(self.on_voice_image_choose)
        self.main_window.mouth_choice.currentIndexChanged.connect(self.on_mouth_choice)
        self.main_window.volume_slider.valueChanged.connect(self.change_volume)
        self.main_window.text_edit.textChanged.connect(self.on_voice_text)
        self.main_window.apply_fps.clicked.connect(self.apply_changed_fps)
        self.main_window.spread_out.clicked.connect(self.spread_out)
        self.main_window.add_tag.clicked.connect(self.add_tag)
        self.main_window.tag_entry.returnPressed.connect(self.add_tag)
        self.main_window.remove_tag.clicked.connect(self.remove_tag)
        self.main_window.apply_voice_change.clicked.connect(self.change_voice_for_selection)
        self.tab_add_button.clicked.connect(self.on_new_voice)
        self.tab_remove_button.clicked.connect(self.on_del_voice)
        self.main_window.current_voice.tabBar().currentChanged.connect(self.on_sel_voice_tab)
        self.recognize_menu = QtWidgets.QMenu()
        self.allo_select = self.recognize_menu.addAction("Allosaurus")
        self.rhubarb_select = self.recognize_menu.addAction("Rhubarb")
        self.allo_select.setCheckable(True)
        self.rhubarb_select.setCheckable(True)
        if self.config.value("/VoiceRecognition/recognizer", "Allosaurus") == "Allosaurus":
            self.allo_select.setChecked(True)
        elif self.config.value("/VoiceRecognition/recognizer", "Allosaurus") == "Rhubarb":
            self.rhubarb_select.setChecked(True)
        self.main_window.connect(self.allo_select, QtCore.SIGNAL("triggered()"),
                                 partial(self.select_voice_recognizer, "Allosaurus"))
        self.main_window.connect(self.rhubarb_select, QtCore.SIGNAL("triggered()"),
                                 partial(self.select_voice_recognizer, "Rhubarb"))
        self.main_window.voice_recognition_button.setMenu(self.recognize_menu)

        self.dropfilter = DropFilter()
        self.main_window.topLevelWidget().installEventFilter(self.dropfilter)
        if not utilities.ffmpeg_binaries_exists():
            self.ffmpeg_action = QtWidgets.QAction("Download FFmpeg")
            self.ffmpeg_action.triggered.connect(lambda: self.start_download(self.download_ffmpeg))
            self.main_window.menubar.addAction(self.ffmpeg_action)
        if not utilities.allosaurus_model_exists():
            self.model_action = QtWidgets.QAction("Download AI Model")
            self.model_action.triggered.connect(lambda: self.start_download(self.download_allosaurus_model))
            self.main_window.menubar.addAction(self.model_action)
        if not utilities.rhubarb_binaries_exists():
            self.rhubarb_action = QtWidgets.QAction("Download Rhubarb")
            self.rhubarb_action.triggered.connect(lambda: self.start_download(self.download_rhubarb))
            self.main_window.menubar.addAction(self.rhubarb_action)
        self.change_stylesheet()
        self.cur_frame = 0
        self.timer = None
        self.wv_height = 1
        self.old_height = self.wv_height
        self.zoom_factor = 1
        self.scroll_position = 0
        self.did_resize = False
        self.wv_pen = QtGui.QPen(QtCore.Qt.darkBlue)
        self.wv_brush = QtGui.QBrush(QtCore.Qt.blue)
        self.start_time = time.time()
        self.threadpool = QtCore.QThreadPool.globalInstance()

    def change_stylesheet(self):
        style_file_path = self.config.value("qss_file_path", "")
        if style_file_path:
            with open(style_file_path, "r") as style_file:
                self.app.setStyleSheet(style_file.read())
        else:
            self.app.setStyleSheet("")

    def download_general_finished(self):
        if utilities.allosaurus_model_exists():
            try:
                self.main_window.menubar.removeAction(self.model_action)
            except AttributeError:
                pass  # was already deleted
        if utilities.ffmpeg_binaries_exists():
            try:
                self.main_window.menubar.removeAction(self.ffmpeg_action)
            except AttributeError:
                pass  # was already deleted
        if utilities.rhubarb_binaries_exists():
            try:
                self.main_window.menubar.removeAction(self.rhubarb_action)
            except AttributeError:
                pass  # was already deleted
        self.status_progress.hide()

    def download_ffmpeg_finished(self):
        self.download_general_finished()
        dlg = QtWidgets.QMessageBox()
        dlg.setText("Download of FFMPEG is finished. \nPlease close and restart Papagayo-NG")
        dlg.setWindowTitle(app_title)
        dlg.setWindowIcon(self.main_window.windowIcon())
        dlg.setStandardButtons(QtWidgets.QMessageBox.Ok)
        dlg.setDefaultButton(QtWidgets.QMessageBox.Ok)
        dlg.setIcon(QtWidgets.QMessageBox.Information)
        dlg.exec_()

    def start_download(self, work_job):
        worker = utilities.Worker(work_job)
        if work_job == self.download_ffmpeg:
            worker.signals.finished.connect(self.download_ffmpeg_finished)
        elif work_job == self.download_allosaurus_model:
            worker.signals.finished.connect(self.download_general_finished)
        elif work_job == self.download_rhubarb:
            worker.signals.finished.connect(self.download_general_finished)
        worker.signals.progress.connect(self.status_bar_progress)
        self.status_progress.show()
        self.status_progress.setMaximum(100)
        self.threadpool.start(worker)

    def status_bar_progress(self, n):
        self.status_progress.setValue(n)
        QtCore.QCoreApplication.processEvents()

    def download_allosaurus_model(self, progress_callback):
        model_name = "latest"
        url = 'https://github.com/xinjli/allosaurus/releases/download/v1.0/' + model_name + '.tar.gz'
        model_dir = os.path.join(utilities.get_app_data_path(), "allosaurus_model")
        with urllib.request.urlopen(url) as req:
            length = req.getheader('content-length')
            block_size = 1000000
            if length:
                length = int(length)
                block_size = max(4096, length // 100)
            buffer_all = io.BytesIO()
            size = 0
            while True:
                buffer_now = req.read(block_size)
                if not buffer_now:
                    break
                buffer_all.write(buffer_now)
                size += len(buffer_now)
                if length:
                    percent = int((size / length) * 100)
                    progress_callback.emit(percent)
            if buffer_all:
                buffer_all.seek(0)
                files = tarfile.open(fileobj=buffer_all)
                files.extractall(str(model_dir))
                os.rename(os.path.join(model_dir, "uni2005"), os.path.join(model_dir, "latest"))
        return

    def download_ffmpeg(self, progress_callback):
        ffmpeg_binary = "ffmpeg.exe"
        ffprobe_binary = "ffprobe.exe"
        ffmpeg_build_url = "https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip"
        ffmpeg_json = json.loads(
            urllib.request.urlopen("https://api.github.com/repos/BtbN/FFmpeg-Builds/releases").read())
        for download in ffmpeg_json[0]["assets"]:
            if download["name"].endswith("win64-lgpl.zip"):
                ffmpeg_build_url = download["browser_download_url"]
        if platform.system() == "Darwin":
            ffmpeg_binary = "ffmpeg"
            ffprobe_binary = "ffprobe"
            ffmpeg_build_url = "https://evermeet.cx/ffmpeg/getrelease/zip"
        ffmpeg_path = os.path.join(utilities.get_app_data_path(), ffmpeg_binary)
        ffprobe_path = os.path.join(utilities.get_app_data_path(), ffprobe_binary)
        if os.path.exists(ffmpeg_path) and os.path.exists(ffprobe_path):
            return
        else:
            try:
                with urllib.request.urlopen(ffmpeg_build_url) as req:
                    length = req.getheader('content-length')
                    block_size = 1000000
                    if length:
                        length = int(length)
                        block_size = max(4096, length // 100)
                    buffer_all = io.BytesIO()
                    size = 0
                    while True:
                        buffer_now = req.read(block_size)
                        if not buffer_now:
                            break
                        buffer_all.write(buffer_now)
                        size += len(buffer_now)
                        if length:
                            percent = int((size / length) * 100)
                            progress_callback.emit(percent)
                    if buffer_all:
                        ffmpeg_zip = ZipFile(buffer_all)
                        for zfile in ffmpeg_zip.filelist:
                            if ffmpeg_binary in zfile.filename:
                                ffmpeg_file_content = ffmpeg_zip.read(zfile.filename)
                                ffmpeg_file = open(ffmpeg_path, "wb")
                                ffmpeg_file.write(ffmpeg_file_content)
                                ffmpeg_file.close()
                            elif ffprobe_binary in zfile.filename:
                                ffprobe_file_content = ffmpeg_zip.read(zfile.filename)
                                ffprobe_file = open(ffprobe_path, "wb")
                                ffprobe_file.write(ffprobe_file_content)
                                ffprobe_file.close()
            except TimeoutError:
                # Download Failed
                pass
            return

    def download_rhubarb(self, progress_callback):
        binary = "/rhubarb/rhubarb.exe"
        release_url = ""
        if platform.system() == "Darwin":
            binary = "/rhubarb/rhubarb"
        github_url = "https://api.github.com/repos/DanielSWolf/rhubarb-lip-sync/releases"
        download_json = json.loads(urllib.request.urlopen(github_url).read())
        for download in download_json[0]["assets"]:
            if platform.system() == "Darwin":
                if download["name"].endswith("-osx.zip"):
                    release_url = download["browser_download_url"]
            else:
                if download["name"].endswith("-win32.zip"):
                    release_url = download["browser_download_url"]
        rhubarb_path = os.path.join(utilities.get_app_data_path(), binary)

        if utilities.rhubarb_binaries_exists():
            return
        else:
            try:
                with urllib.request.urlopen(release_url) as req:
                    length = req.getheader('content-length')
                    block_size = 1000000
                    if length:
                        length = int(length)
                        block_size = max(4096, length // 100)
                    buffer_all = io.BytesIO()
                    size = 0
                    while True:
                        buffer_now = req.read(block_size)
                        if not buffer_now:
                            break
                        buffer_all.write(buffer_now)
                        size += len(buffer_now)
                        if length:
                            percent = int((size / length) * 100)
                            progress_callback.emit(percent)
                    if buffer_all:
                        rhubarb_zip = ZipFile(buffer_all)
                        print(os.path.join(utilities.get_app_data_path(), "rhubarb"))
                        print(rhubarb_zip.filelist)
                        rhubarb_zip.extractall(os.path.join(utilities.get_app_data_path()))
                        dirs = list(set([os.path.dirname(x) for x in rhubarb_zip.namelist()]))
                        main_dir = os.path.dirname([os.path.split(x)[0] for x in dirs][0])
                        os.rename(os.path.join(utilities.get_app_data_path(), main_dir),
                                  os.path.join(utilities.get_app_data_path(), "rhubarb"))
            except TimeoutError:
                # Download Failed
                pass
            return

    def load_ui_widget(self, ui_filename, parent=None):
        self.loader = uic()
        file = QFile(ui_filename)
        file.open(QFile.ReadOnly)
        self.loader.registerCustomWidget(MouthView)
        self.loader.registerCustomWidget(WaveformView)
        self.ui = self.loader.load(file, parent)
        file.close()
        return self.ui

    def set_current_phoneme_set(self, event=None):
        if self.doc:
            phonemeset_name = self.main_window.phoneme_set.currentText()
            self.phonemeset.selected_set = self.phonemeset.load(phonemeset_name)

    def select_voice_recognizer(self, event=None):
        self.config.setValue("/VoiceRecognition/recognizer", event)
        if event == "Allosaurus":
            self.allo_select.setChecked(True)
            self.rhubarb_select.setChecked(False)
        elif event == "Rhubarb":
            self.allo_select.setChecked(False)
            self.rhubarb_select.setChecked(True)

    def change_voice_for_selection(self):
        # TODO: We don't handle overlapping objects yet!
        print("Currently Selected Object: " + self.main_window.waveform_view.currently_selected_object.title)
        print(
            "Corresponding LipsyncObject: " + str(vars(self.main_window.waveform_view.currently_selected_object.node)))
        print("Current Voice: " + self.doc.current_voice.name)
        print("New Voice: " + self.main_window.voice_for_selection.currentText())
        moving_object = self.main_window.waveform_view.currently_selected_object.node
        new_voice_parent = None
        for voice in self.doc.project_node.children:
            if voice.name == self.main_window.voice_for_selection.currentText():
                new_voice_parent = voice
        # Find existing parent object for selected one
        old_parent = moving_object.parent
        parent_instance = old_parent.object_type
        new_parent_object = None

        if parent_instance == "voice":
            new_parent_object = new_voice_parent
            moving_object.parent = new_parent_object
        else:
            for possible_parent in new_voice_parent.children:
                if parent_instance == "phrase":
                    if possible_parent.start_frame <= moving_object.start_frame and possible_parent.end_frame >= moving_object.end_frame:
                        new_parent_object = possible_parent
                elif parent_instance == "word":
                    for possible_word_parent in possible_parent.children:
                        if possible_word_parent.start_frame <= moving_object.start_frame <= possible_word_parent.end_frame:
                            new_parent_object = possible_word_parent
            if not new_parent_object:
                if parent_instance == "phrase":
                    new_temp_parent = LipsyncDoc.LipSyncObject(object_type="phrase", text=moving_object.text,
                                                               start_frame=moving_object.start_frame,
                                                               end_frame=moving_object.end_frame,
                                                               parent=new_voice_parent,
                                                               children=[moving_object])
                    moving_object.parent = new_temp_parent

                if parent_instance == "word":
                    new_temp_parent = LipsyncDoc.LipSyncObject(object_type="phrase", text=moving_object.text,
                                                               start_frame=moving_object.start_frame,
                                                               end_frame=moving_object.end_frame,
                                                               parent=new_voice_parent)
                    new_word_parent = LipsyncDoc.LipSyncObject(object_type="word", text=moving_object.text,
                                                               start_frame=moving_object.start_frame,
                                                               end_frame=moving_object.end_frame,
                                                               parent=new_temp_parent,
                                                               children=[moving_object])
                    moving_object.parent = new_word_parent

            else:
                moving_object.parent = new_parent_object

        if old_parent.object_type == "word":
            phrase_parent = old_parent.parent
            if not old_parent.children:
                old_parent.parent = None
            if not phrase_parent.children:
                phrase_parent.parent = None
        if old_parent.object_type == "phrase":
            if not old_parent.children:
                old_parent.parent = None
        self.main_window.waveform_view.set_document(self.doc, force=True, clear_scene=True)

    def add_tag(self):
        if self.main_window.tag_entry.text():
            self.main_window.list_of_tags.addItem(self.main_window.tag_entry.text())
            self.main_window.tag_entry.clear()
            temp_list = []
            for i in range(self.main_window.list_of_tags.count()):
                temp_list.append(self.main_window.list_of_tags.item(i).text())
            self.main_window.waveform_view.currently_selected_object.set_tags(temp_list)

    def remove_tag(self):
        self.main_window.list_of_tags.takeItem(self.main_window.list_of_tags.currentRow())
        temp_list = []
        for i in range(self.main_window.list_of_tags.count()):
            temp_list.append(self.main_window.list_of_tags.item(i).text())
        self.main_window.waveform_view.currently_selected_object.set_tags(temp_list)

    def spread_out(self):
        wfv = self.main_window.waveform_view
        top_nodes = self.doc.current_voice.children
        num_frames = wfv.waveform_polygon.polygon().boundingRect().width() / wfv.frame_width
        frames_per_top_level = num_frames / len(top_nodes)
        for num, top_node in enumerate(top_nodes):
            top_node.start_frame = round((num * frames_per_top_level) + int(bool(num)))
            top_node.end_frame = round((num * frames_per_top_level) + frames_per_top_level)
            top_node.move_button.after_reposition()
            top_node.move_button.reposition_descendants2(True)

    def apply_changed_fps(self):
        new_fps_value = self.main_window.fps_input.value()
        print('FPS changed to: {0}'.format(str(new_fps_value)))
        old_fps_value = self.doc.fps
        resize_multiplier = new_fps_value / old_fps_value
        if resize_multiplier != 1:
            self.doc.fps = new_fps_value
            wfv = self.main_window.waveform_view
            wfv.samples_per_sec = self.doc.fps * wfv.samples_per_frame
            wfv.start_recalc(True)
            wfv.scene().setSceneRect(wfv.scene().sceneRect().x(), wfv.scene().sceneRect().y(),
                                     wfv.sceneRect().width() * resize_multiplier, wfv.scene().sceneRect().height())
            wfv.setSceneRect(wfv.scene().sceneRect())
            wfv.scroll_position *= resize_multiplier
            wfv.scroll_position = 0
            wfv.horizontalScrollBar().setValue(wfv.scroll_position)
            self.doc.project_node.sound_duration = int(self.doc.sound.Duration() * self.doc.fps)

    def on_voice_recognize(self):
        if self.doc and self.doc.sound:
            if len(self.doc.project_node.children) < 1:
                self.doc.current_voice = LipsyncDoc.LipSyncObject(object_type="voice", name="Voice 1",
                                                                  parent=self.doc.project_node)
            else:
                self.doc.current_voice.children = []
            self.doc.auto_recognize_phoneme(manual_invoke=True)
            self.main_window.waveform_view.set_document(self.doc, force=True, clear_scene=True)
            self.main_window.mouth_view.set_document(self.doc)

    def close_doc_ok(self):
        if self.doc is not None:
            if not self.doc.dirty:
                return True
            dlg = QtWidgets.QMessageBox()
            dlg.setText("Save changes to this project?")
            dlg.setStandardButtons(QtWidgets.QMessageBox.Yes | QtWidgets.QMessageBox.No)
            dlg.setDefaultButton(QtWidgets.QMessageBox.Yes)
            dlg.setIcon(QtWidgets.QMessageBox.Question)
            result = dlg.exec_()
            if result == QtWidgets.QMessageBox.Yes:
                self.on_save()
                if not self.doc.dirty:
                    self.config.setValue("LastFPS", str(self.doc.fps))
                    return True
                else:
                    return False
            elif result == QtWidgets.QMessageBox.No:
                self.config.setValue("LastFPS", str(self.doc.fps))
                return True
            elif result == QtWidgets.QMessageBox.Cancel:
                return False
        else:
            return True

    def on_open(self):
        if not self.close_doc_ok():
            return
        file_path, _ = QtWidgets.QFileDialog.getOpenFileName(self.main_window,
                                                             "Open Audio or {} File".format(app_title),
                                                             self.config.value("WorkingDir", utilities.get_main_dir()),
                                                             open_wildcard)
        if file_path:
            self.config.setValue("WorkingDir", os.path.dirname(file_path))
            self.open(file_path)

    def open(self, path):
        while self.main_window.current_voice.tabBar().count() > 1:
            self.main_window.current_voice.tabBar().removeTab(self.main_window.current_voice.tabBar().count() - 1)
        self.doc = LipsyncDoc.LipsyncDoc(self.langman, self)
        if path.endswith(lipsync_extension_list):
            if path.endswith(lipsync_extension_list[0]):
                # open a lipsync project
                self.doc.open(path)
            elif path.endswith(lipsync_extension_list[1]):
                # open a json based lipsync project
                self.doc.open_json(path)
            while self.doc.sound is None:
                # if no sound file found, then ask user to specify one
                dlg = QtWidgets.QMessageBox(self.main_window)
                dlg.setText('Please load correct audio file')
                dlg.setWindowTitle(app_title)
                dlg.setIcon(QtWidgets.QMessageBox.Warning)
                dlg.exec_()  # This should open it as a modal blocking window
                file_path = QtWidgets.QFileDialog.getOpenFileName(self.main_window,
                                                                  "Open Audio",
                                                                  self.config.value("WorkingDir",
                                                                                    utilities.get_main_dir()),
                                                                  audio_extensions)[0]
                if file_path:
                    self.doc.open_audio(file_path)
        else:
            # open an audio file
            self.doc.fps = int(self.config.value("LastFPS", 24))
            self.doc.open_audio(path)
            if self.doc.sound is None:
                self.doc = None
            else:
                if len(self.doc.project_node.children) < 1:
                    self.doc.current_voice = LipsyncDoc.LipSyncObject(object_type="voice", name="Voice 1",
                                                                      parent=self.doc.project_node)
                elif not self.doc.current_voice:
                    self.doc.current_voice = self.doc.project_node.children[0]
                self.doc.auto_recognize_phoneme()
                # check for a .trans file with the same name as the doc
                try:
                    txt_file = open("{}.trans".format(path[0].rsplit('.', 1)[0]), 'r')  # TODO: Check if path is correct
                    for line in txt_file:
                        self.main_window.current_voice.tabBar().addTab(QtGui.QStandardItem(line))
                except:
                    pass
        if self.doc is not None:
            self.main_window.setWindowTitle("{} [{}] - {}".format(self.doc.name, path, app_title))
            self.main_window.waveform_view.first_update = True
            self.main_window.waveform_view.set_document(self.doc, force=True, clear_scene=True)
            self.main_window.mouth_view.set_document(self.doc)
            # Reenable all disabled widgets TODO: Can likely be reduced
            self.main_window.vertical_layout_right.setEnabled(True)
            self.main_window.vertical_layout_left.setEnabled(True)
            self.main_window.volume_slider.setEnabled(True)
            self.main_window.volume_slider.setValue(int(self.config.value("volume", 50)))
            self.main_window.action_save.setEnabled(True)
            self.main_window.action_save_as.setEnabled(True)
            self.main_window.action_cut.setEnabled(True)
            self.main_window.action_cut.triggered.connect(self.on_del_object)
            self.main_window.menu_edit.setEnabled(True)
            self.main_window.choose_imageset_button.setEnabled(False)
            self.main_window.action_convert_phonemes.triggered.connect(self.doc.convert_to_phonemeset)
            if self.doc.sound is not None:
                self.main_window.action_play.setEnabled(True)
                # self.main_window.action_stop.setEnabled(True)
                self.main_window.action_zoom_in.setEnabled(True)
                self.main_window.action_zoom_out.setEnabled(True)
                self.main_window.action_reset_zoom.setEnabled(True)
            self.main_window.tag_list_group.setEnabled(False)
            list_of_voices = [voice.name for voice in self.doc.project_node.children]
            self.main_window.voice_for_selection.clear()
            self.main_window.voice_for_selection.addItems(list_of_voices)
            current_index = self.main_window.phoneme_set.findText(self.phonemeset.selected_set)
            self.main_window.phoneme_set.setCurrentIndex(current_index)

            first_entry = True
            for voice in self.doc.project_node.children:
                if not first_entry:
                    self.main_window.current_voice.tabBar().addTab(voice.name)
                else:
                    self.main_window.current_voice.tabBar().setTabText(0, voice.name)
                    first_entry = False
            self.main_window.fps_input.setValue(self.doc.fps)
            self.main_window.voice_name_input.setText(self.doc.current_voice.name)
            self.main_window.text_edit.setText(self.doc.current_voice.text)

            # reload dictionary
            self.on_reload_dictionary()
            self.doc.dirty = False

    def on_save(self):
        if self.doc is None:
            return
        if self.doc.path is None:
            self.on_save_as()
            return
        if self.doc.path.endswith(lipsync_extension_list[0]):
            self.doc.save(self.doc.path)
        elif self.doc.path.endswith(lipsync_extension_list[1]):
            self.doc.save2(self.doc.path)

    def on_save_as(self):
        if self.doc is None:
            return
        file_path, _ = QtWidgets.QFileDialog.getSaveFileName(self.main_window,
                                                             "Save {} File".format(app_title),
                                                             self.config.value("WorkingDir", utilities.get_main_dir()),
                                                             save_wildcard)
        if file_path:
            self.config.setValue("WorkingDir", os.path.dirname(file_path))
            if file_path.endswith(lipsync_extension_list[0]):
                self.doc.save(file_path)
            elif file_path.endswith(lipsync_extension_list[1]):
                self.doc.save2(file_path)
            self.main_window.setWindowTitle("{} [{}] - {}".format(self.doc.name, file_path, app_title))

    def on_close(self):
        if self.doc is not None:
            self.close_doc_ok()
            self.config.setValue("LastFPS", str(self.doc.fps))
            del self.doc
        self.doc = None
        self.main_window.waveform_view.first_update = True
        self.main_window.waveform_view.set_document(self.doc)
        # clear voice controls
        self.main_window.voice_name_input.clear()
        self.main_window.text_edit.clear()
        self.main_window.fps_input.clear()
        # disabling widgets
        self.main_window.vertical_layout_right.setEnabled(False)
        self.main_window.vertical_layout_left.setEnabled(False)
        self.main_window.volume_slider.setEnabled(False)
        self.main_window.action_save.setEnabled(False)
        self.main_window.action_save_as.setEnabled(False)
        self.main_window.menu_edit.setEnabled(False)
        self.main_window.action_play.setEnabled(False)
        self.main_window.action_stop.setEnabled(False)
        self.main_window.action_zoom_in.setEnabled(False)
        self.main_window.action_zoom_out.setEnabled(False)
        self.main_window.action_reset_zoom.setEnabled(False)

    def on_quit(self, event=None):
        self.on_close()
        self.close(True)

    def on_help(self, event=None):
        github_path = "https://github.com/morevnaproject/papagayo-ng/issues"
        test_path = "file://{}".format(r"D:\Program Files (x86)\Papagayo\help\index.html")
        real_path = "file://{}".format(os.path.join(utilities.get_main_dir(), "help", "index.html"))
        QtGui.QDesktopServices.openUrl(github_path)

    def on_about(self, event=None):
        self.about_dlg = AboutBox()
        self.about_dlg.main_window.show()

    def show_settings(self, event=None):
        self.settings_dlg = SettingsWindow()
        self.settings_dlg.main_window.show()
        self.settings_dlg.main_window.finished.connect(self.settings_closed)

    def settings_closed(self):
        if not utilities.ffmpeg_binaries_exists():
            self.ffmpeg_action = QtWidgets.QAction("Download FFmpeg")
            self.ffmpeg_action.triggered.connect(lambda: self.start_download(self.download_ffmpeg))
            self.main_window.menubar.addAction(self.ffmpeg_action)
        if not utilities.allosaurus_model_exists():
            self.model_action = QtWidgets.QAction("Download AI Model")
            self.model_action.triggered.connect(lambda: self.start_download(self.download_allosaurus_model))
            self.main_window.menubar.addAction(self.model_action)
        if not utilities.rhubarb_binaries_exists():
            self.rhubarb_action = QtWidgets.QAction("Download Rhubarb")
            self.rhubarb_action.triggered.connect(lambda: self.start_download(self.download_rhubarb))
            self.main_window.menubar.addAction(self.rhubarb_action)
        self.main_window.waveform_view.set_document(self.doc, True, True)
        if self.config.value("/VoiceRecognition/recognizer", "Allosaurus") == "Allosaurus":
            self.allo_select.setChecked(True)
            self.rhubarb_select.setChecked(False)
        elif self.config.value("/VoiceRecognition/recognizer", "Allosaurus") == "Rhubarb":
            self.rhubarb_select.setChecked(True)
            self.allo_select.setChecked(False)
        self.change_stylesheet()

    def on_play(self, event=None):
        if (self.doc is not None) and (self.doc.sound is not None):
            self.cur_frame = -1
            self.main_window.action_play.setEnabled(False)
            self.main_window.action_stop.setEnabled(True)
            self.doc.sound.set_cur_time(0)
            self.doc.sound.play(False)
            self.timer = QtCore.QTimer()
            self.main_window.waveform_view.temp_play_marker.setVisible(True)
            self.timer.timeout.connect(self.on_play_tick)
            # self.connect(self.timer, None, self.on_play_tick)
            self.timer.start(250.0 / self.doc.fps)

    def on_stop(self, event=None):
        if (self.doc is not None) and (self.doc.sound is not None):
            self.doc.sound.stop()
            self.doc.sound.set_cur_time(0)
            self.main_window.waveform_view.temp_play_marker.setVisible(False)
            self.main_window.mouth_view.set_frame(0)
            self.main_window.waveform_view.set_frame(0)
            self.main_window.action_stop.setEnabled(False)
            self.main_window.action_play.setEnabled(True)
            self.main_window.statusbar.showMessage("Stopped")
            self.main_window.waveform_view.horizontalScrollBar().setValue(
                self.main_window.waveform_view.scroll_position)
            self.main_window.waveform_view.update()
            QtCore.QCoreApplication.processEvents()

    def on_play_tick(self, event=None):
        if (self.doc is not None) and (self.doc.sound is not None):
            if self.doc.sound.is_playing():
                cur_frame = int(self.doc.sound.current_time() * self.doc.fps)
                if self.cur_frame != cur_frame:
                    self.cur_frame = cur_frame
                    self.main_window.mouth_view.set_frame(self.cur_frame)
                    self.main_window.waveform_view.set_frame(self.cur_frame)
                    try:
                        fps = 1.0 / (time.time() - self.start_time)
                    except ZeroDivisionError:
                        fps = 60
                    self.main_window.statusbar.showMessage("Frame: {:d} FPS: {:d}".format((cur_frame + 1), int(fps)))
                    self.main_window.waveform_view.scroll_position = self.main_window.waveform_view.horizontalScrollBar().value()
                    self.start_time = time.time()
            else:
                self.main_window.waveform_view.temp_play_marker.setVisible(False)
                self.on_stop()
                self.timer.stop()
                del self.timer

    def change_volume(self, e):
        if self.doc and self.doc.sound:
            self.doc.sound.set_volume(int(self.main_window.volume_slider.value()))
            self.config.setValue("volume", int(self.main_window.volume_slider.value()))

    def on_mouth_choice(self, event=None):
        self.main_window.mouth_view.current_mouth = self.main_window.mouth_choice.currentText()
        self.main_window.mouth_view.draw_me()

    def on_export_choice(self, event=None):
        if self.main_window.export_combo.currentText() == "Images":
            self.main_window.choose_imageset_button.setEnabled(True)
        else:
            self.main_window.choose_imageset_button.setEnabled(False)

    def on_voice_name(self, event=None):

        if (self.doc is not None) and (self.doc.current_voice is not None):
            self.doc.dirty = True
            self.doc.current_voice.name = self.main_window.voice_name_input.text()
            self.main_window.voice_name_input.setText(self.doc.current_voice.name)
            self.main_window.current_voice.tabBar().setTabText(self.main_window.current_voice.tabBar().currentIndex(),
                                                               self.doc.current_voice.name)
            self.main_window.waveform_view.first_update = True
            self.main_window.waveform_view.set_document(self.doc)

    def on_voice_text(self, event=None):
        if self.ignore_text_changes:
            return
        if (self.doc is not None) and (self.doc.current_voice is not None):
            self.doc.dirty = True
            self.doc.current_voice.text = self.main_window.text_edit.toPlainText()

    def on_voice_breakdown(self, event=None):
        if (self.doc is not None) and (self.doc.current_voice is not None):
            language = self.main_window.language_choice.currentText()
            phonemeset_name = self.main_window.phoneme_set.currentText()
            self.doc.dirty = True
            self.doc.current_voice.children = []
            self.doc.current_voice.run_breakdown(self.doc.soundDuration, self, language, self.langman,
                                                 self.phonemeset)
            self.phonemeset.selected_set = self.phonemeset.load(phonemeset_name)
            self.main_window.waveform_view.first_update = True
            self.ignore_text_changes = True
            self.main_window.text_edit.setText(self.doc.current_voice.text)
            self.ignore_text_changes = False
            self.main_window.waveform_view.set_document(self.doc, True, True)

    def on_voice_export(self, event=None):
        language = self.main_window.language_choice.currentText()
        if (self.doc is not None) and (self.doc.current_voice is not None):
            exporter = self.main_window.export_combo.currentText()
            message = ""
            default_file = ""
            wildcard = ""
            if exporter == "MOHO":
                message = "Export Lipsync Data (MOHO)"
                default_file = "{}".format(self.doc.soundPath.rsplit('.', 1)[0]) + ".dat"
                wildcard = "Moho switch files (*.dat)"
            elif exporter == "ALELO":
                fps = int(self.config.value("FPS", 24))
                if fps != 100:
                    dlg = QtWidgets.QMessageBox()
                    dlg.setText("FPS is NOT 100 continue? (You will have issues downstream.)")
                    dlg.setStandardButtons(QtWidgets.QMessageBox.Yes | QtWidgets.QMessageBox.No)
                    dlg.setDefaultButton(QtWidgets.QMessageBox.Yes)
                    dlg.setIcon(QtWidgets.QMessageBox.Question)
                    result = dlg.exec_()
                    if result == QtWidgets.QMessageBox.Yes:
                        message = "Export Lipsync Data (ALELO)"
                        default_file = "{}.txt".format(self.doc.soundPath.rsplit('.', 1)[0])
                        wildcard = "Alelo timing files (*.txt)|*.txt"
                    elif result == QtWidgets.QMessageBox.No:
                        return
                    elif result == QtWidgets.QMessageBox.Cancel:
                        return
                else:
                    message = "Export Lipsync Data (ALELO)"
                    default_file = "{}.txt".format(self.doc.soundPath.rsplit('.', 1)[0])
                    wildcard = "Alelo timing files (*.txt)|*.txt"
            elif exporter == "Images":
                message = "Export Image Strip"
                default_file = "{}".format(self.doc.soundPath.rsplit('.', 1)[0])
                wildcard = ""
            elif exporter == "JSON":
                message = "Export JSON Object"
                default_file = "{}.json".format(self.doc.soundPath.rsplit('.', 1)[0])
                wildcard = "JSON object files (*.json)|*.json"
            file_path, _ = QtWidgets.QFileDialog.getSaveFileName(self.main_window,
                                                                 message,
                                                                 default_file,
                                                                 wildcard,
                                                                 options=QtWidgets.QFileDialog.DontUseNativeDialog)
            if file_path:
                self.config.setValue("WorkingDir", os.path.dirname(file_path))
                if exporter == "MOHO":
                    self.doc.current_voice.export(file_path if ("." in file_path) else file_path + ".dat")
                elif exporter == "ALELO":
                    self.doc.current_voice.export_alelo(file_path, language, self.langman)
                elif exporter == "Images":
                    self.doc.current_voice.export_images(file_path, self.main_window.mouth_choice.currentText())
                elif exporter == "JSON":
                    self.doc.current_voice.export_json(file_path)

    def on_sel_voice_tab(self, e):
        if not self.doc:
            return
        prev_dirty = self.doc.dirty
        self.ignore_text_changes = True
        for voice in self.doc.project_node.children:
            if voice.name == self.main_window.current_voice.tabBar().tabText(
                    self.main_window.current_voice.tabBar().currentIndex()):
                self.doc.current_voice = voice

        self.main_window.list_of_tags.clear()
        self.main_window.tag_list_group.setEnabled(False)
        self.main_window.voice_name_input.setText(self.doc.current_voice.name)
        self.main_window.text_edit.setText(self.doc.current_voice.text)
        self.ignore_text_changes = False
        self.main_window.voice_for_selection.setCurrentIndex(self.main_window.current_voice.tabBar().currentIndex())
        self.main_window.waveform_view.set_document(self.doc, True)
        self.main_window.mouth_view.draw_me()
        self.doc.dirty = prev_dirty

    def on_new_voice(self, event=None):
        if not self.doc:
            return
        self.doc.dirty = True
        voice_exist_count = 1
        new_voice_name = "Voice {:d}".format(len(self.doc.project_node.children) + voice_exist_count)
        voice_name_exists = True
        while voice_name_exists:
            voice_name_exists = False
            new_voice_name = "Voice {:d}".format(len(self.doc.project_node.children) + voice_exist_count)
            for voice in self.doc.project_node.children:
                if voice.name == new_voice_name:
                    voice_name_exists = True
                    voice_exist_count += 1
                    break

        self.doc.current_voice = LipsyncDoc.LipSyncObject(object_type="voice", name=new_voice_name,
                                                          parent=self.doc.project_node)
        self.main_window.current_voice.tabBar().addTab(self.doc.current_voice.name)
        self.main_window.current_voice.tabBar().setCurrentIndex(self.main_window.current_voice.tabBar().count() - 1)
        self.ignore_text_changes = True
        self.main_window.voice_name_input.setText(self.doc.current_voice.name)
        self.main_window.text_edit.setText(self.doc.current_voice.text)
        self.ignore_text_changes = False
        list_of_voices = [voice.name for voice in self.doc.project_node.children]
        self.main_window.voice_for_selection.clear()
        self.main_window.voice_for_selection.addItems(list_of_voices)
        self.main_window.voice_for_selection.setCurrentIndex(self.main_window.current_voice.tabBar().count() - 1)
        self.main_window.waveform_view.set_document(self.doc, True)
        self.main_window.mouth_view.draw_me()

    def on_del_object(self):
        self.main_window.waveform_view.currently_selected_object.node.parent = None
        all_delete_items = []
        all_delete_items.extend(self.main_window.waveform_view.currently_selected_object.node.descendants)
        all_delete_items.append(self.main_window.waveform_view.currently_selected_object.node)
        for item in self.main_window.waveform_view.scene().items():
            if isinstance(item, QtWidgets.QGraphicsProxyWidget):
                for to_delete in all_delete_items:
                    if item.widget() == to_delete.move_button:
                        self.main_window.waveform_view.scene().removeItem(item)
        del self.main_window.waveform_view.currently_selected_object.node

    def on_del_voice(self, event=None):
        if (not self.doc) or (len(self.doc.project_node.children) == 1):
            return
        self.doc.dirty = True
        new_index = self.doc.project_node.children.index(self.doc.current_voice)
        if new_index > 0:
            new_index -= 1
        else:
            new_index = 0
        self.doc.current_voice.parent = None
        del self.doc.current_voice
        self.doc.current_voice = self.doc.project_node.children[new_index]
        self.main_window.voice_name_input.setText(self.doc.current_voice.name)
        self.main_window.text_edit.setText(self.doc.current_voice.text)
        self.main_window.current_voice.tabBar().removeTab(self.main_window.current_voice.tabBar().currentIndex())
        list_of_voices = [voice.name for voice in self.doc.project_node.children]
        self.main_window.voice_for_selection.clear()
        self.main_window.voice_for_selection.addItems(list_of_voices)
        self.main_window.voice_for_selection.setCurrentIndex(new_index)
        self.main_window.waveform_view.set_document(self.doc, True, True)
        self.main_window.mouth_view.draw_me()

    def on_voice_image_choose(self, event=None):
        language = self.main_window.language_choice.currentText()
        if (self.doc is not None) and (self.doc.current_voice is not None):
            voiceimage_path = QtWidgets.QFileDialog.getExistingDirectory(self.main_window,
                                                                         "Choose Path for Images",
                                                                         self.config.value("MouthDir",
                                                                                           os.path.join(os.path.dirname(
                                                                                               os.path.abspath(
                                                                                                   __file__)),
                                                                                               "rsrc",
                                                                                               r"mouths/")))
            if voiceimage_path:
                self.config.setValue("MouthDir", voiceimage_path)
                supported_imagetypes = QtGui.QImageReader.supportedImageFormats()
                for directory, dir_names, file_names in os.walk(voiceimage_path):
                    self.main_window.mouth_view.process_mouth_dir(directory, file_names, supported_imagetypes)
                mouth_list = list(self.main_window.mouth_view.mouths.keys())
                mouth_list.sort(key=sort_mouth_list_order)
                self.main_window.mouth_choice.clear()
                for mouth in mouth_list:
                    self.main_window.mouth_choice.addItem(mouth)
                self.main_window.mouth_choice.setCurrentIndex(
                    self.main_window.mouth_choice.findText(os.path.basename(voiceimage_path)))
                self.main_window.mouth_view.current_mouth = self.main_window.mouth_choice.currentText()

    def on_reload_dictionary(self, event=None):
        print("reload the dictionary")
        lang_config = self.doc.language_manager.language_table[self.main_window.language_choice.currentText()]
        self.doc.language_manager.load_language(lang_config, force=True)

    def quit_application(self):
        sys.exit(self.app.exec_())

# end of class LipsyncFrame
